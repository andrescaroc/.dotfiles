[language-server.rust-analyzer.config.check]
command = "clippy"

[language-server.lsp-ai]
command = "lsp-ai"
timeout = 300

# The entire configuration is passed in this 'config' object
[language-server.lsp-ai.config]

# THIS SECTION WAS MISSING. The server requires it to be defined.
[language-server.lsp-ai.config.memory]
file_store = { }

# Define all models under a single 'models' table
[language-server.lsp-ai.config.models]
[language-server.lsp-ai.config.models.model1]
type = "ollama"
model = "deepseek-r1:1.5b"
chat_endpoint = "http://localhost:11434/api/chat"
generate_endpoint = "http://localhost:11434/api/generate"
max_requests_per_second = 1

[[language-server.lsp-ai.config.chat]]
trigger = "!C"
action_display_name = "Chat"
model = "model1"

[language-server.lsp-ai.config.chat.parameters]
max_context = 4096
max_tokens = 1024

[[language-server.lsp-ai.config.chat.parameters.messages]]
role = "system"
content = "You are a code assistant chatbot. The user will ask you for assistance coding and you will do you best to answer succinctly and accurately"

[[language-server.lsp-ai.config.chat]]
trigger = "!CC"
action_display_name = "Chat with context"
model = "model1"

[language-server.lsp-ai.config.chat.parameters]
max_context = 4096
max_tokens = 1024

[[language-server.lsp-ai.config.chat.parameters.messages]]
role = "system"
content = "You are a code assistant chatbot. The user will ask you for assistance coding and you will do you best to answer succinctly and accurately given the code context:\n\n{CONTEXT}"

[language-server.lsp-ai.config.models.model2]
type = "ollama"
model = "qwen2.5-coder:1.5b"
chat_endpoint = "http://localhost:11434/api/chat"
generate_endpoint = "http://localhost:11434/api/generate"
max_requests_per_second = 1

# Configure the standard code completion feature
[language-server.lsp-ai.config.completion]
model = "model2"

[language-server.lsp-ai.config.completion.parameters]
max_tokens = 64
max_context = 2000

[language-server.lsp-ai.config.completion.parameters.options]
num_predict = 32

[language-server.lsp-ai.config.completion.parameters.fim]
start = "<fim_prefix>"
middle = "<fim_suffix>"
end = "<fim_middle>"

# We keep the generic system prompt, as it's excellent.
[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "system"
content = "Instructions:\n- You are an AI programming assistant.\n- Given a piece of code with the cursor location marked by \"<CURSOR>\", replace \"<CURSOR>\" with the correct code or comment.\n- First, think step-by-step.\n- Describe your plan for what to build in pseudocode, written out in great detail.\n- Then output the code replacing the \"<CURSOR>\"\n- Ensure that your completion fits within the language context of the provided code snippet (e.g., Python, JavaScript, Rust).\n\nRules:\n- Only respond with code or comments.\n- Only replace \"<CURSOR>\"; do not include any previously written code.\n- Never include \"<CURSOR>\" in your response\n- If the cursor is within a comment, complete the comment meaningfully.\n- Handle ambiguous cases by providing the most contextually appropriate completion.\n- Be consistent with your responses."

# --- Few-shot examples tailored for Rust ---

# Example 1: Function body completion
[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "fn multiply(a: i32, b: i32) -> i32 {\n    a * <CURSOR>\n}"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "b"

# Example 2: Completing a println! macro
[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "fn greet(name: &str) {\n    println!(\"Hello, {}\", <CURSOR>);\n}"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "name"

# Example 3: Completing a comment
[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "// This struct holds user data\n<CURSOR>"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "struct User {\n    username: String,\n    id: u64,\n}"

# The final, required message that sends your actual code
[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "{CODE}"

# -- Language Mappings --

[[language]]
name = "rust"
language-servers = ["rust-analyzer", "lsp-ai"]

[[language]]
name = "yaml"
language-servers = ["lsp-ai"]

[[language]]
name = "markdown"
language-servers = ["markdown-oxide", "lsp-ai"]
